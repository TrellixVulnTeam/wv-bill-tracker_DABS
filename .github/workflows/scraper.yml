name: Run Scraper

on:
  schedule:
    - cron: "0 */3 * * *"
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - uses: actions/checkout@v2
        with:
          path: main

      - name: Install pip
        working-directory: main/scraper
        run: python -m pip install --upgrade pip

      - name: Install bs
        working-directory: main/scraper
        run: pip install bs4

      - name: Install requests
        working-directory: main/scraper
        run: pip install requests

      - name: Install dateutil
        working-directory: main/scraper
        run: pip install python-dateutil

      - name: Install pytz
        working-directory: main/scraper
        run: pip install pytz

      - name: Run scaper
        working-directory: main/scraper
        run: python scraper.py

      - name: Save to s3
        uses: prewk/s3-cp-action@v2
        with:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          source: 'main/scraper/bills.json'
          dest: 's3://projects.mountainstatespotlight.org/scraper/bills.json'
  call-deploy:
    uses: ./.github/workflows/deploy.yml
    secrets:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
